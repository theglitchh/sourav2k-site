<head>
    <link rel='stylesheet' href='report.css'>
    <link rel="icon" href="S.png">
    <title>Sourav</title>
    <meta charset="UTF-8">

    <meta name='viewport' content='width=device-width, initial-scale=1.0'>
    <meta property="og:title" content="Sourav">
    <meta property="og:description" content="Sourav's Introductory website">
</head>

<body>
<div class="blogtopics">
    <p class="heading">Paper 1: Face Expression Recognition and Analysis: The State of the Art Bettadapura, V. (2012).</p>
    <p class="des">From this paper we learnt about the facial parameterization using Face Action Units (AUs) and MPEG-4 Facial Animation Parameters (FAPs)
    which helped us to convert raw data's to mp4's for displaying detected images</p>
    <div class="hcenter">

        <a href='https://arxiv.org/abs/1203.6722'>
            <button class="btn">
                Paper Link 1
            </button>
        </a>

    </div>
    <p class="heading">Paper 2: Facial expression recognition based on facial components detection and hog features Chi. Z, & Fu H, 2014.
    </p>
    <p class="des">From this paper we took some ideas about the free available datasets present as a open study (opensource)
    and how we can train the data's and convert them to hdf5(dataset blob).</p>

    <div class="hcenter">

        <a href='http://www.cedus.it/documents/SicurezzaUrbana/Videosorveglianza_e_altre_tecnologie_video_di_controllo/3ZChi_ACV-1.pdf'>
            <button class="btn">
                Paper Link 2
            </button>
        </a>

    </div>
    <p class="heading">Paper 3: Real time facial expression
        recognition in video using support vector machines.

    </p>
    <p class="des">From this paper we selected the two bulked datasets which are opensource and free for all
        I: COHN-KANADE AU Coded Facial Expression Dataset,  II: FER-2013, III: Japanese Female Facial Expression (JAFFE) Dataset.
    </p>

    <div class="hcenter">

        <a href='https://www.cs.cmu.edu/~pmichel/publications/Michel-RTFacExpRecSVM.pdf'>
            <button class="btn">
                Paper Link 3
            </button>
        </a>

    </div>
    <p class="heading">Paper 4: Robust facial
        expression learning using binary techniques Shan, C., Gong, S., & McOwan, P. W. (2005, September).

    </p>
    <p class="des">From this paper we have the learnt the basic knowledge of how the face expression works and how
        we can detect the face emotions using the facial parameters like AU's and FAP's.
    </p>

    <div class="hcenter">

        <a href='https://www.researchgate.net/publication/4186342_Robust_facial_expression_recognition_using_local_binary_patterns'>
            <button class="btn">
                Paper Link 4
            </button>
        </a>
    </div>
</div>

</body>
<footer>
    <a href='https://github.com/thefallnn'>
        <p class="footer-credit">Â© 2023 Courtesy of TheFallnn (Sourav Gope) </p>
    </a>

</footer>